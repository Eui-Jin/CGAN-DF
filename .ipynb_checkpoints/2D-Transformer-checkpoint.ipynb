{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Concatenate, Layer, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, Flatten,LeakyReLU,ReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from functools import partial\n",
    "from gumbel_softmax import GumbelSoftmax\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "pd.options.display.max_rows = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Class\n",
    "## Implement  multi-head attention as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a Transformer block as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Implement a Transformer block as a layer\n",
    "\"\"\"\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Class 3. Implement 1D-Positional encoding and 2D-Locational encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding1D, self).__init__()\n",
    "        self.channels = channels\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 3d tensor of size (batch_size, x, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 3:\n",
    "            raise RuntimeError(\"The input tensor has to be 3d!\")\n",
    "        _, x, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1)\n",
    "        emb = torch.zeros((x,self.channels),device=tensor.device).type(tensor.type())\n",
    "        emb[:,:self.channels] = emb_x\n",
    "\n",
    "        return emb[None,:,:orig_ch]\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding2D, self).__init__()\n",
    "        channels = int(np.ceil(channels/2))\n",
    "        self.channels = channels\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param tensor: A 4d tensor of size (batch_size, x, y, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise RuntimeError(\"The input tensor has to be 4d!\")\n",
    "        _, x, y, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1).unsqueeze(1)\n",
    "        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1)\n",
    "        emb = torch.zeros((x,y,self.channels*2),device=tensor.device).type(tensor.type())\n",
    "        emb[:,:,:self.channels] = emb_x\n",
    "        emb[:,:,self.channels:2*self.channels] = emb_y\n",
    "        return emb[None,:,:,:orig_ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution() ## For implementing WGAN-GP in training process \n",
    "gpu = tf.config.experimental.get_visible_devices('GPU')[0] ## Identify the GPU\n",
    "tf.config.experimental.set_memory_growth(device = gpu, enable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the sample data\n",
    "   * Large-scale incomplete data (Smart card data)\n",
    "       * (Input) Trip-chain attributes (y_train_SC_seq)\n",
    "       * (Input) General attributes (y_train_SC_nseq)\n",
    "   * Small-scale complete data (Travel survey data)\n",
    "       * (Input) Trip-chain attributes (y_train_seq)\n",
    "       * (Input) General attributes (y_train_nseq)\n",
    "       * (Output) Qualitative attributes (x_train_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_SC_seq = np.load('Data/y_train_SC_seq.npy',allow_pickle=True)\n",
    "y_test_SC_seq = np.load('Data/y_test_SC_seq.npy',allow_pickle=True)\n",
    "y_train_seq = np.load('Data/y_train_seq.npy',allow_pickle=True)\n",
    "y_test_seq = np.load('Data/y_test_seq.npy',allow_pickle=True)\n",
    "\n",
    "y_train_nseq= pd.read_csv('Data/y_train_nseq.csv')\n",
    "y_test_nseq= pd.read_csv('Data/y_test_nseq.csv')\n",
    "y_train_SC_nseq= pd.read_csv('Data/y_train_SC_nseq.csv')\n",
    "y_test_SC_nseq= pd.read_csv('Data/y_test_SC_nseq.csv')\n",
    "x_train_cond= pd.read_csv('Data/x_train_cond.csv')\n",
    "x_test_cond= pd.read_csv('Data/x_test_cond.csv')\n",
    "\n",
    "## Qualitative attrubutes in the raw small-scale complete data\n",
    "x_train_cond_R = pd.read_csv('Data/train_complete_qualitative.csv')\n",
    "y_test_cond_SC_R = pd.read_csv('Data/train_incomplete_tripChain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = y_train_seq.shape[2]-4 # The number of input variables including sequential information\n",
    "maxlen = 5  # The number of maximum sequence of trip-chain\n",
    "num_data = y_train_seq.shape[0] # The number of individuals in training data (complete)\n",
    "num_data_SC = y_train_SC_seq.shape[0] # The number of individuals in training data (incomplete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function for 1D-Positional and 2D-Locational encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1D Positional Encoding (numbpy implementation)\n",
    "def seq(data, data_len):\n",
    "    \n",
    "    pos_encoding = PositionalEncoding1D(num_features)\n",
    "    d = torch.zeros((1,maxlen,num_features))\n",
    "    pos_1d_emb = pos_encoding(d) \n",
    "    pos_1d_emb = pos_1d_emb.numpy()\n",
    "    \n",
    "    pos_seq_emb = []\n",
    "    for i in range(data_len):\n",
    "        for j in range(maxlen):\n",
    "            a = int(data[i,j,num_features+3])\n",
    "            if a == 1 :\n",
    "                b = pos_1d_emb[:,0,:]\n",
    "            elif a == 2:\n",
    "                b = pos_1d_emb[:,1,:]\n",
    "            elif a == 3:\n",
    "                b = pos_1d_emb[:,2,:]\n",
    "            elif a == 4:\n",
    "                b = pos_1d_emb[:,3,:]\n",
    "            elif a == 5:\n",
    "                b = pos_1d_emb[:,4,:]\n",
    "            else :\n",
    "                b = np.zeros((1,num_features))\n",
    "            pos_seq_emb.append(b)\n",
    "    pos_seq_emb=np.array(pos_seq_emb)\n",
    "    pos_seq_emb=pos_seq_emb.reshape(data_len,maxlen,num_features)  \n",
    "    \n",
    "    for k in range(4):\n",
    "        data = np.delete(data,num_features, axis=2)\n",
    "    \n",
    "\n",
    "    data_seq = data + pos_seq_emb\n",
    "    \n",
    "    return data_seq\n",
    "\n",
    "## 2D Lositional Encoding (numbpy implementation)\n",
    "def selo(data, data_len):\n",
    "    pos_encoding = PositionalEncoding1D(num_features)\n",
    "    d = torch.zeros((1,maxlen,num_features))\n",
    "    pos_1d_emb = pos_encoding(d) \n",
    "    pos_1d_emb = pos_1d_emb.numpy()\n",
    "    \n",
    "    pos_seq_emb = []    \n",
    "    for i in range(data_len):\n",
    "        for j in range(maxlen):\n",
    "            a = int(data[i,j,num_features+3])\n",
    "            if a == 1 :\n",
    "                b = pos_1d_emb[:,0,:]\n",
    "            elif a == 2:\n",
    "                b = pos_1d_emb[:,1,:]\n",
    "            elif a == 3:\n",
    "                b = pos_1d_emb[:,2,:]\n",
    "            elif a == 4:\n",
    "                b = pos_1d_emb[:,3,:]\n",
    "            elif a == 5:\n",
    "                b = pos_1d_emb[:,4,:]\n",
    "            else :\n",
    "                b = np.zeros((1,num_features))\n",
    "            pos_seq_emb.append(b)\n",
    "    pos_seq_emb=np.array(pos_seq_emb)\n",
    "    pos_seq_emb=pos_seq_emb.reshape(data_len,maxlen,num_features)\n",
    "    \n",
    "    p_enc_2d = PositionalEncoding2D(num_features)\n",
    "    m = torch.zeros((1,95,40,num_features)) # 21 by 21 grids\n",
    "    pos_2d_emb = p_enc_2d(m)\n",
    "    pos_2d_emb = pos_2d_emb.numpy()\n",
    "    pos_2d_emb[:,0,0,:] = 0\n",
    "    \n",
    "    pos_loc_emb = []    \n",
    "    for i in range(data_len):           \n",
    "        a=pos_2d_emb[:,int(data[i,0,num_features]),int(data[i,0,num_features+1]),:]\n",
    "        b=pos_2d_emb[:,int(data[i,1,num_features]),int(data[i,1,num_features+1]),:]\n",
    "        c=pos_2d_emb[:,int(data[i,2,num_features]),int(data[i,2,num_features+1]),:]\n",
    "        d=pos_2d_emb[:,int(data[i,3,num_features]),int(data[i,3,num_features+1]),:]\n",
    "        e=pos_2d_emb[:,int(data[i,4,num_features]),int(data[i,4,num_features+1]),:]\n",
    "        pos_loc_emb.append(a)\n",
    "        pos_loc_emb.append(b)\n",
    "        pos_loc_emb.append(c)\n",
    "        pos_loc_emb.append(d)\n",
    "        pos_loc_emb.append(e)\n",
    "    pos_loc_emb=np.array(pos_loc_emb)\n",
    "    pos_loc_emb=np.reshape(pos_loc_emb, (data_len,maxlen,num_features))\n",
    "    \n",
    "    for k in range(4):\n",
    "        data = np.delete(data,num_features, axis=2)\n",
    "\n",
    "\n",
    "    data_seq_loc = data + pos_seq_emb + pos_loc_emb\n",
    "    \n",
    "    return data_seq_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Applying the positional and locational encoding to the trip-chain attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq_1d = seq(y_train_seq,len(y_train_seq)) # complete trip-chain attributes with 1D-positional encoding\n",
    "y_train_seq_2d = selo(y_train_seq,len(y_train_seq)) # complete trip-chain attributes with 1D-positional and 2D-locational encoding\n",
    "y_train_SC_seq_1d = seq(y_train_SC_seq,len(y_train_SC_seq)) # incomplete trip-chain attributes with 1D-positional encoding\n",
    "y_train_SC_seq_2d = selo(y_train_SC_seq,len(y_train_SC_seq)) # incomplete trip-chain attributes with 1D-positional and 2D-locational encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build WGAN-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise = Input(shape=(latent_dim))\n",
    "    label_ns = Input(shape=(nseq_dim))  \n",
    "    label = Input(shape=(maxlen,embed_dim))\n",
    "    \n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(label)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    \n",
    "    k = Flatten()(x)   \n",
    "    \n",
    "    inputs = Concatenate()([noise,label_ns,k])  \n",
    "    \n",
    "    h = Dense(intermediate_dim[0])(inputs)\n",
    "    #h = BatchNormalization()(h) \n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    h = Dense(intermediate_dim[1])(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    h = Dense(intermediate_dim[2])(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "   \n",
    "\n",
    "    cat_outputs = [] # Six socioeconomic factors (Qualitative attributes)\n",
    "    for i in ['Home_income', 'Home_car', 'Home_drive', 'Age', 'Gender','Home_type']:\n",
    "        t = Dense(x_train_cond_R[i].nunique())(h)\n",
    "        #t = Activation('softmax')(t) # You can choose the softmax rather than gumbel\n",
    "        t = gumbel(t,6)\n",
    "        cat_outputs.append(t)\n",
    "    \n",
    "    tp_outputs = [] # Trip purposes of each trip in the trip-chain (Qualitative attributes)\n",
    "    p = Dense(48,activation='relu')(x)\n",
    "    p = Dense(24,activation='relu')(p)\n",
    "    p = Dense(12,activation='relu')(p)\n",
    "    for i in range(5):\n",
    "        t = Dense(6)(p[:,i,:])\n",
    "        #t = Activation('softmax')(t) # You can choose the softmax rather than gumbel \n",
    "        t = gumbel(t,6)\n",
    "        cat_outputs.append(t)\n",
    "                                 \n",
    "       \n",
    "    concat = Concatenate()(cat_outputs)\n",
    "    \n",
    "    \n",
    "    model = Model([noise,label_ns,label],concat)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build critic(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_critic():\n",
    "    \n",
    "    img = Input(shape=x_train_cond.shape[1])\n",
    "    label = Input(shape=(maxlen,embed_dim))\n",
    "    label_ns = Input(shape=(nseq_dim))  \n",
    "    \n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(label)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    inputs = Concatenate()([img,label_ns,x])  \n",
    "\n",
    "    h = Dense(intermediate_dim[2])(inputs)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    h = Dense(intermediate_dim[1])(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    h = Dense(intermediate_dim[0])(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    validity = Dense(1)(h)\n",
    "    \n",
    "    model = Model(inputs = [img,label_ns,label],outputs = validity)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define functions for WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def RandomWeightedAverage(inputs):\n",
    "    alpha = K.random_uniform((BATCH_SIZE, 1))\n",
    "    return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameter Setting for Conditional WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting hyperparameters from MultiCATGAN\n",
    "intermediate_dim = [256,256,256]\n",
    "latent_dim = 128\n",
    "optimizer = Adam(lr=2e-04) ## \n",
    "BATCH_SIZE = 256\n",
    "gumbel = GumbelSoftmax(name = 'gumbel')\n",
    "embed_dim = num_features\n",
    "nseq_dim = y_train_nseq.shape[1]\n",
    "num_heads = 4\n",
    "ff_dim = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Conditional WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Build\n",
    "generator = build_generator()\n",
    "critic = build_critic()\n",
    "\n",
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#       for the Critic\n",
    "#-------------------------------\n",
    "\n",
    "## Freeze generator's layers while training critic\n",
    "generator.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "# Image input (real sample)\n",
    "real_img = Input(shape=x_train_cond.shape[1])\n",
    "\n",
    "# Noise input\n",
    "z_disc = Input(shape=(latent_dim))\n",
    "# Generate image based of noise (fake sample) and add label to the input \n",
    "label = Input(shape=(maxlen,embed_dim))\n",
    "label_ns = Input(shape=(nseq_dim))  \n",
    "fake_img = generator([z_disc,label_ns,label])\n",
    "\n",
    "# Discriminator determines validity of the real and fake images\n",
    "fake = critic([fake_img,label_ns,label])\n",
    "valid = critic([real_img,label_ns,label])\n",
    "\n",
    "\n",
    "# Construct weighted average between real and fake images\n",
    "interpolated_img = RandomWeightedAverage([real_img, fake_img])\n",
    "\n",
    "# Determine validity of weighted sample\n",
    "validity_interpolated = critic([interpolated_img,label_ns,label])\n",
    "\n",
    "partial_gp_loss = partial(gradient_penalty_loss,averaged_samples=interpolated_img)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "critic_model = Model(inputs=[real_img,label_ns,label,z_disc], outputs=[valid, fake, validity_interpolated])\n",
    "critic_model.compile(loss=[wasserstein_loss,\n",
    "                           wasserstein_loss,\n",
    "                           partial_gp_loss],\n",
    "                           optimizer=optimizer,\n",
    "                           loss_weights=[1, 1, 10])\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#         for Generator\n",
    "#-------------------------------\n",
    "\n",
    "# For the generator we freeze the critic's layers\n",
    "critic.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "# Sampled noise for input to generator\n",
    "z_gen = Input(shape=(latent_dim))\n",
    "# add label to the input\n",
    "label = Input(shape=(maxlen,embed_dim))\n",
    "label_ns = Input(shape=(nseq_dim))  \n",
    "# Generate images based of noise\n",
    "img = generator([z_gen,label_ns,label])\n",
    "\n",
    "# Discriminator determines validity\n",
    "valid = critic([img,label_ns,label])\n",
    "\n",
    "# Defines generator model\n",
    "generator_model = Model([z_gen,label_ns,label], valid)\n",
    "generator_model.compile(loss=wasserstein_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "## Train\n",
    "epochs = 40000 # 1 hours 7000\n",
    "sample_interval = 500\n",
    "n_critic = 5\n",
    "BATCH_SIZE = 256\n",
    "losslog = []\n",
    "\n",
    "# Load the dataset\n",
    "X_train = x_train_cond.values.astype(\"float32\")\n",
    "y_train = y_train_seq_2d\n",
    "y_train_ns = y_train_nseq.values.astype(\"float32\")\n",
    "y_train_SC = y_train_SC_seq_2d\n",
    "y_train_SC_ns = y_train_SC_nseq.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Adversarial ground truths\n",
    "valid = - np.ones(BATCH_SIZE)\n",
    "fake =  np.ones(BATCH_SIZE)\n",
    "dummy = np.zeros(BATCH_SIZE) # Dummy gt for gradient penalty\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(n_critic):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random batch of images\n",
    "        \n",
    "        \n",
    "        idx = np.random.randint(0,X_train.shape[0],BATCH_SIZE)\n",
    "        imgs, labels, labels_ns = X_train[idx], y_train[idx], y_train_ns[idx]\n",
    "\n",
    "        # Sample generator input\n",
    "        noise = np.random.normal(0,1,[BATCH_SIZE,latent_dim]) \n",
    "        # Train the critic\n",
    "        d_loss = critic_model.train_on_batch([imgs, labels_ns,labels, noise], [valid, fake, dummy])\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "    idx_SC = np.random.randint(0, y_train_SC.shape[0], BATCH_SIZE)\n",
    "    sampled_labels,sampled_labels_ns = y_train_SC[idx_SC],y_train_SC_ns[idx_SC]\n",
    "    g_loss = generator_model.train_on_batch([noise,sampled_labels_ns,sampled_labels], valid)\n",
    "\n",
    "    # Plot the progress\n",
    "    # Plot the progress\n",
    "\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "        losslog.append([d_loss[0], g_loss])\n",
    "        generator.save_weights('Py_generator/AttnMO_XY_F1', overwrite=True)\n",
    "        critic.save_weights('Py_critic/AttnMO_XY_F1', overwrite=True)\n",
    "        \n",
    "        \n",
    "print(\"time :\", time.time() - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the qualitative attributes using generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for evaluation\n",
    "## Convert the dummy qualitative attributes into categorical one\n",
    "def wide_to_long(samples_pop):\n",
    "    resamples = []\n",
    "    for j in range(samples_pop.shape[0]):\n",
    "        if(type(samples_pop) is np.ndarray):\n",
    "            sam = samples_pop[j]\n",
    "        else:\n",
    "            sam = samples_pop.values[j]\n",
    "        resamples_row = []\n",
    "        for i in range(len(n_uni_col)-1):\n",
    "            idx = range(n_uni_col[i],n_uni_col[i+1])\n",
    "            resamples_row = np.append(resamples_row,np.random.choice(col_pop[idx],p=sam[idx],size=1))\n",
    "        resamples = np.concatenate((resamples,resamples_row),axis=0)\n",
    "    resamples = resamples.reshape(samples_pop.shape[0],len(n_uni_col)-1 )\n",
    "    resamples = pd.DataFrame(resamples,columns= x_train_cond_R.columns[1:7].to_list()+[\"TP_0\",\"TP_1\",\"TP_2\",\"TP_3\",\"TP_4\"])\n",
    "    resamples = resamples.apply(lambda x: x.astype('category'))\n",
    "    return(resamples)\n",
    "\n",
    "## Calculate the mean Jenson-Shannon Distance\n",
    "def mean_JSD(samples,resamples):\n",
    "    Marg_JSD = []\n",
    "    for col in samples.columns:\n",
    "        resam = pd.value_counts(resamples[col]).sort_index()\n",
    "        sam = pd.value_counts(samples[col]).sort_index()\n",
    "        tab = pd.merge(resam,sam,left_index=True, right_index=True,how='outer')\n",
    "        tab = tab.fillna(0)\n",
    "        Marg_JSD.append(jensenshannon(tab.iloc[:,0], tab.iloc[:,1]))\n",
    "     \n",
    "\n",
    "    bi_index = combinations(samples.columns,2)\n",
    "    bi_index = list(bi_index)\n",
    "    col1,col2 = bi_index[0]\n",
    "\n",
    "    Bi_JSD = []\n",
    "    for col1,col2 in bi_index:\n",
    "        resam = pd.DataFrame(pd.crosstab(resamples[col1],resamples[col2],rownames=[col1],colnames=[col2]).stack().sort_index())\n",
    "        sam = pd.DataFrame(pd.crosstab(samples[col1],samples[col2],rownames=[col1],colnames=[col2]).stack().sort_index())\n",
    "        tab = pd.merge(resam,sam,left_index=True, right_index=True,how='outer')\n",
    "        tab = tab.fillna(0)\n",
    "        Bi_JSD.append(jensenshannon(tab.iloc[:,0], tab.iloc[:,1]))\n",
    "\n",
    "    return([Marg_JSD,Bi_JSD])\n",
    "\n",
    "# ## Calculate the mean Jenson-Shannon Distanc\n",
    "\n",
    "# def get_resamples(y_test_SC_seq,y_test_SC_nseq_ns,num_gen=1):\n",
    "#     resamples_SC = pd.DataFrame()\n",
    "#     for i in range(num_gen):\n",
    "#         y_test_SC = selo(y_test_SC_seq,len(y_test_SC_seq))\n",
    "#         y_test_SC_ns = y_test_SC_nseq.values.astype(\"float32\")\n",
    "#         idx = sample(range(y_test_SC.shape[0]),x_test_cond.shape[0])\n",
    "#         samples_act = y_test_SC[idx,:]\n",
    "#         samples_act_ns = y_test_SC_ns[idx,:]\n",
    "#         samples_pop_SC = generate_images(samples_act,samples_act_ns)\n",
    "#         resamples_SC = pd.concat([resamples_SC,wide_to_long(samples_pop_SC)],axis=0)\n",
    "#     return(resamples_SC)\n",
    "\n",
    "# Define the generator function\n",
    "def generate_images(label,label_ns):\n",
    "    generator.load_weights('Py_generator/AttnMO_XY_F1')\n",
    "    noise = np.random.normal(0, 1, (label.shape[0],latent_dim))\n",
    "    gen_imgs = generator.predict([noise,label_ns,label])\n",
    "   \n",
    "    \n",
    "    return gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euijin\\Anaconda3\\envs\\C8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "# Generate the qualitative attributes of smart card\n",
    "y_test_SC = selo(y_test_SC_seq,len(y_test_SC_seq))\n",
    "y_test_SC_ns = y_test_SC_nseq.values.astype(\"float32\")\n",
    "\n",
    "samples_act = y_test_SC\n",
    "samples_act_ns = y_test_SC_ns\n",
    "samples_pop_SC = generate_images(samples_act,samples_act_ns)\n",
    "\n",
    "\n",
    "\n",
    "# Generate the qualitative attributes of travel survey (For validation)\n",
    "y_test_TS = selo(y_test_seq,len(y_test_seq))\n",
    "y_test_TS_ns = y_test_nseq.values.astype(\"float32\")\n",
    "idx = sample(range(y_test_TS.shape[0]),x_test_cond.shape[0])\n",
    "\n",
    "samples_act = y_test_TS[idx,:]\n",
    "samples_act_ns = y_test_TS_ns[idx,:]\n",
    "samples_pop = generate_images(samples_act,samples_act_ns)\n",
    "\n",
    "\n",
    "\n",
    "## Make Ground Truth & Test\n",
    "n_uni_col = [x_train_cond_R[i].nunique() for i in x_train_cond_R.columns[1:7]]\n",
    "n_uni_col = [0]+n_uni_col+[6,6,6,6,6]\n",
    "n_uni_col = np.cumsum(n_uni_col)\n",
    "col_pop = x_test_cond.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = wide_to_long(x_test_cond)\n",
    "resamples = wide_to_long(samples_pop)\n",
    "resamples_SC = wide_to_long(samples_pop_SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the determinisic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6181818181818222\n",
      "0.659177957762484\n",
      "0.02379644426114808 0.049980293012139146\n"
     ]
    }
   ],
   "source": [
    "## Compute deterministic accuracy\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "## NHTS case\n",
    "y_test_SC = selo(y_test_seq,len(y_test_seq))\n",
    "y_test_SC_ns = y_test_nseq.values.astype(\"float32\")\n",
    "\n",
    "## ensembles\n",
    "resamples_ensemble = []\n",
    "for i in range(10):\n",
    "    resamples_ensemble.append(wide_to_long(generate_images(y_test_SC,y_test_SC_ns)))\n",
    "array_ensemble = np.array(resamples_ensemble)\n",
    "   \n",
    "\n",
    "## 1. Hamming Distance\n",
    "def hamming_loss_cat(y_true,y_pred):\n",
    "    hamming_cat = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        hamming_cat += distance.hamming(y_true[i,:],y_pred[i,:])\n",
    "    return (hamming_cat/y_true.shape[0])\n",
    "\n",
    "## 2. Ensemble Hamming Distance\n",
    "def ensemble_hamming_loss_cat(y_true,y_pred):\n",
    "    hamming_cat = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        majority = []\n",
    "        for j in range(y_true.shape[1]):\n",
    "            majority.append(random.choice(y_pred[:,i,j]))\n",
    "        hamming_cat += distance.hamming(y_true[i,:],np.array(majority,dtype=object))\n",
    "    return (hamming_cat/y_true.shape[0])\n",
    "\n",
    "                            \n",
    "print(1-hamming_loss_cat(np.array(samples),np.array(resamples)))\n",
    "print(1-ensemble_hamming_loss_cat(np.array(samples),np.array(array_ensemble)))\n",
    "\n",
    "## 3. Ensemble JSD\n",
    "majority = []\n",
    "for i in range(samples.shape[0]):\n",
    "    for j in range(samples.shape[1]):\n",
    "        majority.append(random.choice(array_ensemble[:,i,j]))\n",
    "majority = np.array(majority).reshape((samples.shape[0],samples.shape[1]))\n",
    "majority = pd.DataFrame(majority,columns = samples.columns)        \n",
    "\n",
    "Marg_JSD,Bi_JSD = mean_JSD(samples,majority)\n",
    "print(np.mean(Marg_JSD),np.mean(Bi_JSD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the distributional distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Jensen-Shannon distance (JSD) of marginal or bivariate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07468955613207197 0.12422619124587404\n",
      "0.023361587071332925 0.04893103699461636\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "from itertools import combinations\n",
    "\n",
    "# JSD between the qualitative attributes of travel survey vs generated smart card\n",
    "Marg_JSD,Bi_JSD = mean_JSD(samples,resamples_SC)\n",
    "print(np.mean(Marg_JSD),np.mean(Bi_JSD))\n",
    "\n",
    "# JSD between the qualitative attributes of travel survey vs generated travel survety\n",
    "Marg_JSD,Bi_JSD = mean_JSD(samples,resamples)\n",
    "print(np.mean(Marg_JSD),np.mean(Bi_JSD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the fidelity and diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Precision and Recall implmented by Naeem, M.F., Oh, S.J., Uh, Y., Choi, Y., Yoo, J., 2020. Reliable fidelity and diversity metrics for generative models. 37th Int. Conf. Mach. Learn. ICML 2020 PartF16814, 7133–7142. https://arxiv.org/abs/2002.09797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precision & Recall 2\n",
    "import numpy as np\n",
    "from prdc import compute_prdc\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics\n",
    "\n",
    "def compute_pairwise_distance(data_x, data_y=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_x: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        data_y: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "    Returns:\n",
    "        numpy.ndarray([N, N], dtype=np.float32) of pairwise distances.\n",
    "    \"\"\"\n",
    "    if data_y is None:\n",
    "        data_y = data_x\n",
    "    dists = sklearn.metrics.pairwise_distances(\n",
    "        data_x, data_y, metric='l1', n_jobs=8)\n",
    "    return dists\n",
    "\n",
    "\n",
    "def get_kth_value(unsorted, k, axis=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        unsorted: numpy.ndarray of any dimensionality.\n",
    "        k: int\n",
    "    Returns:\n",
    "        kth values along the designated axis.\n",
    "    \"\"\"\n",
    "    indices = np.argpartition(unsorted, k, axis=axis)[..., :k]\n",
    "    k_smallests = np.take_along_axis(unsorted, indices, axis=axis)\n",
    "    kth_values = k_smallests.max(axis=axis)\n",
    "    return kth_values\n",
    "\n",
    "\n",
    "def compute_nearest_neighbour_distances(input_features, nearest_k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        nearest_k: int\n",
    "    Returns:\n",
    "        Distances to kth nearest neighbours.\n",
    "    \"\"\"\n",
    "    distances = compute_pairwise_distance(input_features)\n",
    "    radii = get_kth_value(distances, k=nearest_k + 1, axis=-1)\n",
    "    return radii\n",
    "\n",
    "        \n",
    "def compute_prdc(real_features, fake_features, nearest_k):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, density, and coverage given two manifolds.\n",
    "    Args:\n",
    "        real_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        fake_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        nearest_k: int.\n",
    "    Returns:\n",
    "        dict of precision, recall, density, and coverage.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Num real: {} Num fake: {}'\n",
    "          .format(real_features.shape[0], fake_features.shape[0]))\n",
    "\n",
    "    real_nearest_neighbour_distances = compute_nearest_neighbour_distances(\n",
    "        real_features, nearest_k)\n",
    "    fake_nearest_neighbour_distances = compute_nearest_neighbour_distances(\n",
    "        fake_features, nearest_k)\n",
    "    distance_real_fake = compute_pairwise_distance(\n",
    "        real_features, fake_features)\n",
    "       \n",
    "\n",
    "    precision = (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(real_nearest_neighbour_distances, axis=1)\n",
    "    ).any(axis=0).mean()\n",
    "\n",
    "    recall = (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(fake_nearest_neighbour_distances, axis=0)\n",
    "    ).any(axis=1).mean()\n",
    "\n",
    "    density = (1. / float(nearest_k)) * (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(real_nearest_neighbour_distances, axis=1)\n",
    "    ).sum(axis=0).mean()\n",
    "\n",
    "    coverage = (\n",
    "            distance_real_fake.min(axis=1) <\n",
    "            real_nearest_neighbour_distances\n",
    "    ).mean()\n",
    "\n",
    "    return dict(precision=precision, recall=recall,\n",
    "                density=density, coverage=coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the pretrained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num real: 6005 Num fake: 25000\n",
      "{'precision': 0.76512, 'recall': 0.9728559533721899, 'density': 0.4918628571428571, 'coverage': 0.6664446294754371}\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained bert model\n",
    "mlm_model = tf.keras.models.load_model(\n",
    "    \"MLM_Embed_indiv.h5\")\n",
    "\n",
    "embedding_layers =  mlm_model.layers[11:22]\n",
    "\n",
    "def convert_to_embedding(samples):\n",
    "    samples_emb = []\n",
    "    for i in range(len(embedding_layers)):\n",
    "        emb_weight = embedding_layers[i].get_weights()[0]\n",
    "        trgt = samples[:,range(n_uni_col[i],n_uni_col[i+1])]\n",
    "        samples_emb.append(np.dot(trgt,emb_weight))\n",
    "    \n",
    "    return(np.concatenate(samples_emb,axis=1))\n",
    "\n",
    "\n",
    "nearest_k = 7\n",
    "metrics = compute_prdc(real_features=convert_to_embedding(np.array(x_test_cond)),\n",
    "                       fake_features=convert_to_embedding(np.array(pd.DataFrame(samples_pop_SC))),\n",
    "                       nearest_k=nearest_k)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the creativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mode-Seeking implemented by Mao, Q., Lee, H.Y., Tseng, H.Y., Ma, S., Yang, M.H., 2019. Mode seeking generative adversarial networks for diverse image synthesis. Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. 2019-June, 1429–1437. https://doi.org/10.1109/CVPR.2019.00152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09555928275884486\n"
     ]
    }
   ],
   "source": [
    "# Mode_Seeking Loss\n",
    "generator.load_weights('Py_generator/AttnMO_XY_F1')\n",
    "noise = np.random.normal(0, 1, ((samples_act.shape[0]-1),latent_dim))\n",
    "noise1, noise2 = np.split(noise ,2,axis=0)\n",
    "\n",
    "img1 = generator.predict([noise1,samples_act_ns,samples_act])\n",
    "img2 = generator.predict([noise2,samples_act_ns,samples_act])\n",
    "\n",
    "modeseek_loss = np.mean(np.abs(img1-img2)) / np.mean(np.abs(noise1-noise2))\n",
    "print(modeseek_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5853c2d75344d9b1fb0696953ce9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=5, ncols=2)\n",
    "ax = np.reshape(ax,(-1))\n",
    "colors = ['red', 'lime']\n",
    "label=['Generated', 'Training']\n",
    "\n",
    "i=0\n",
    "for i in range(len(samples.columns[:-1])):\n",
    "    \n",
    "    resam = pd.value_counts(resamples.iloc[:,i]).sort_index()\n",
    "    sam = pd.value_counts(samples.iloc[:,i]).sort_index()\n",
    "    tab = pd.merge(resam,sam,left_index=True, right_index=True,how='right')\n",
    "    tab = tab.fillna(0)\n",
    "    ticks = np.arange(tab.shape[0])\n",
    "    w = 0.3\n",
    "    ax[i].bar(ticks-0.5*w,tab.iloc[:,0],align='center',width =  w,color=colors[0], label=label[0])\n",
    "    ax[i].bar(ticks+0.5*w,tab.iloc[:,1],align='center',width =  w,color=colors[1], label=label[1])\n",
    "    ax[i].set_title(samples.columns[i],fontsize=8)\n",
    "    ax[i].tick_params(axis='y', labelsize=5)\n",
    "    #ax[i].autoscale(tight=True)\n",
    "    ax[i].set_xticks(ticks)\n",
    "    ax[i].set_xticklabels(labels = tab.index.to_list(),fontsize=5,rotation=40)\n",
    "\n",
    "plt.subplots_adjust(left=0.15, right=0.85, top=0.90,bottom=0.10,wspace = 0.2,hspace=0.2)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,12)\n",
    "plt.rcParams[\"legend.loc\"] = 'upper right'\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('line_plot_hq.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trip purposes according to activity duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8290fbfeb25743b2affc41c2b40affce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sample data\n",
    "# ## SC_Gen\n",
    "T_TP=np.concatenate([np.array(resamples_SC.iloc[:,6:11]).reshape((-1,1)),np.array(y_test_SC_seq[:,:,21:41]).reshape((-1,20))],axis=1)\n",
    "ActicityDuration = np.argmax(T_TP[:,1:21],axis=1)\n",
    "T_TP=pd.DataFrame({'TP' : T_TP[:,0],'AD':ActicityDuration})\n",
    "T_TP['TP'] = [T_TP['TP'].iloc[x][-1] for x in range(T_TP['TP'].shape[0])]\n",
    "T_TP=T_TP[-(T_TP['TP'] == 'Z')]\n",
    "\n",
    "T_TP_CNT_0 = T_TP[T_TP['TP']=='0'].groupby('AD').count()\n",
    "T_TP_CNT_1 = T_TP[T_TP['TP']=='1'].groupby('AD').count()\n",
    "T_TP_CNT_2 = T_TP[T_TP['TP']=='2'].groupby('AD').count()\n",
    "T_TP_CNT_3 = T_TP[T_TP['TP']=='3'].groupby('AD').count()\n",
    "T_TP_CNT_4 = T_TP[T_TP['TP']=='4'].groupby('AD').count()\n",
    "\n",
    "T_TP_CNT = pd.concat([T_TP_CNT_0,T_TP_CNT_1,T_TP_CNT_2,T_TP_CNT_3,T_TP_CNT_4],axis=1)\n",
    "T_TP_CNT.columns = ['Commute','Work','Organized Hobby','Entertainment','Returning Home']\n",
    "T_TP_CNT = T_TP_CNT.loc[[9,0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19],:]\n",
    "T_TP_CNT.index = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "T_TP_CNT.plot(xticks = [0,2,4,6,8,10,12,14,16,18],style='o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trip purposes according to arrival time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6923fc9d73c4aa1802b63cb938a7f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sample data\n",
    "# ## SC_Gen\n",
    "T_TP=np.concatenate([np.array(resamples_SC.iloc[:,6:11]).reshape((-1,1)),np.array(y_test_SC_seq[:,:,2:21]).reshape((-1,19))],axis=1)\n",
    "Arrival_Time = np.argmax(T_TP[:,1:20],axis=1)\n",
    "T_TP=pd.DataFrame({'TP' : T_TP[:,0],'AT':Arrival_Time})\n",
    "T_TP['TP'] = [T_TP['TP'].iloc[x][-1] for x in range(T_TP['TP'].shape[0])]\n",
    "T_TP=T_TP[-(T_TP['TP'] == 'Z')]\n",
    "\n",
    "T_TP_CNT_0 = T_TP[T_TP['TP']=='0'].groupby('AT').count()\n",
    "T_TP_CNT_1 = T_TP[T_TP['TP']=='1'].groupby('AT').count()\n",
    "T_TP_CNT_2 = T_TP[T_TP['TP']=='2'].groupby('AT').count()\n",
    "T_TP_CNT_3 = T_TP[T_TP['TP']=='3'].groupby('AT').count()\n",
    "T_TP_CNT_4 = T_TP[T_TP['TP']=='4'].groupby('AT').count()\n",
    "\n",
    "T_TP_CNT = pd.concat([T_TP_CNT_0,T_TP_CNT_1,T_TP_CNT_2,T_TP_CNT_3,T_TP_CNT_4],axis=1)\n",
    "T_TP_CNT.columns = ['Commute','Work','Organized Hobby','Entertainment','Returning Home']\n",
    "T_TP_CNT.index = [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "\n",
    "\n",
    "T_TP_CNT.plot(xticks=[5,7,9,11,13,15,17,19,21,23],style='o-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
